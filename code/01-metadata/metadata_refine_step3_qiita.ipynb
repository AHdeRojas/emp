{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**author**: lukethompson@gmail.com<br>\n",
    "**date**: 5 October 2017<br>\n",
    "**language**: Python 3.5<br>\n",
    "**conda environment**: emp-py3<br>\n",
    "**license**: BSD3<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ORDER OF SCRIPTS: ***\n",
    "1. metadata_refine_step1_studies.ipynb\n",
    "2. metadata_refine_step2_samples.ipynb\n",
    "3. metadata_refine_step3_qiita.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** STUDIES WITH MAPPING FILES PROCESSED IN STEP 2 NOTEBOOK THAT REQUIRE SPECIAL HANLING: ***\n",
    "\n",
    "* 1889, 10146 -- missing sample info files in Qiita -- IGNORE BC NOT IN EMP PAPER\n",
    "* 10246, 10278, 10346 -- mapping file has fewer samples than sample info file -- IGNORE BC NOT IN EMP PAPER\n",
    "* 1033, 1696, 2229 -- mapping file has fewer samples than sample info file -- FIX SAMPLE INFO MANUALLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to retrieve the sample info files (by Qiita admin only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from qiita_db.study import Study\n",
    "# from shutil import copy\n",
    "# from os import mkdir\n",
    "\n",
    "# ffp = '/home/qiita/emp-sample-info-files'\n",
    "# study_ids = [  550,   632,   638,   659,   662,   678,   713,   714,   722,   723,\n",
    "#                755,   776,   804,   805,   807,   808,   809,   810,   829,   846,\n",
    "#                861,   864,   865,   889,   894,   895,   905,   910,   925,   933,\n",
    "#                940,   945,   958,   963,   990,  1001,  1024,  1030,  1031,  1033,\n",
    "#               1034,  1035,  1036,  1037,  1038,  1039,  1041,  1043,  1056,  1064,\n",
    "#               1098,  1197,  1198,  1222,  1235,  1240,  1242,  1288,  1289,  1453,\n",
    "#               1481,  1521,  1526,  1578,  1579,  1580,  1621,  1622,  1627,  1632,\n",
    "#               1642,  1665,  1673,  1674,  1692,  1694,  1696,  1702,  1711,  1713,\n",
    "#               1714,  1715,  1716,  1717,  1721,  1734,  1736,  1747,  1748,  1773,\n",
    "#               1774,  1795,  1799,  1883,  1889,  2080,  2182,  2192,  2229,  2300,\n",
    "#               2318,  2338,  2382, 10145, 10146, 10156, 10171, 10172, 10180, 10245,\n",
    "#              10246, 10247, 10248, 10273, 10278, 10308, 10323, 10346, 10363, 10522,\n",
    "#              10533, 10581]\n",
    "# studies = [Study(s) for s in study_ids]\n",
    "# mkdir(ffp)\n",
    "# [copy(s.sample_template.get_filepaths()[0][1], ffp)\n",
    "# for s in studies if s.sample_template is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porting refined EMP metadata to Qiita sample info files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_refined = '../../data/metadata-refine/emp_qiime_mapping_refined_YYYYMMDD.tsv'\n",
    "path_ids = '../../data/metadata-refine/refine_emp_studies_ct112.txt'\n",
    "path_plan = '../../data/metadata-refine/qiita_add_replace_columns.xlsx'\n",
    "path_sample_info = '../../data/metadata-refine/metadata-sample-info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "studies = set([line.rstrip('\\n') for line in open(path_ids)])\n",
    "\n",
    "# remove studies where mapping file has fewer samples than sample info file -- ignore\n",
    "studies = studies - {'10246', '10278', '10346'}\n",
    "# remove studies where mapping file has fewer samples than sample info file -- these will be fixed manually\n",
    "studies = studies - {'1033', '1696', '2229'}\n",
    "# remove studies where sample names don't match (10146 is prepended twice!)\n",
    "studies = studies - {'10146'}\n",
    "# NOW: DON'T remove these studies bc sample info files ARE in Qiita (studies not in EMP paper)\n",
    "#studies = studies - {'1889'}\n",
    "\n",
    "# convert to sorted list of strings\n",
    "studies = list(studies)\n",
    "studies = [int(x) for x in studies]\n",
    "studies.sort()\n",
    "studies = [str(x) for x in studies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "problem_studies = ['1033', '1696', '2229', '10146', '10246', '10278', '10346']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_refined = pd.read_csv(path_refined, sep='\\t', index_col=0, dtype=object, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_plan = pd.read_excel(path_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace or add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for study_id in studies:\n",
    "    \n",
    "    df = pd.read_csv('%s/%s_sample_info.tsv' % (path_sample_info, study_id), sep='\\t', index_col=0)\n",
    "    \n",
    "    df_new = df.copy(deep=True)\n",
    "    df_diff = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for index, row in df_plan.iterrows():\n",
    "\n",
    "        old_cols = row.old_column.split(',')\n",
    "        newcol = ''\n",
    "        \n",
    "        if row.action == 'replace always':\n",
    "            # drop all old columns if they exist\n",
    "            for old_col in old_cols:\n",
    "                if old_col in df_new.columns:\n",
    "                    df_new.drop(old_col, axis=1, inplace=True)\n",
    "            # add new column always\n",
    "            newcol = [df_refined.loc[i, row.new_column] for i in df_new.index]\n",
    "            df_new[row.new_column] = newcol\n",
    "            df_diff[row.new_column] = newcol\n",
    "\n",
    "        elif row.action == 'replace if':\n",
    "            # check if any old columns exist\n",
    "            if np.any([x in df_new.columns for x in old_cols]):\n",
    "                # drop old column if it exists\n",
    "                for old_col in old_cols:\n",
    "                    if old_col in df_new.columns:\n",
    "                        df_new.drop(old_col, axis=1, inplace=True)        \n",
    "                # add new column if old column exists\n",
    "                newcol = [df_refined.loc[i, row.new_column] for i in df_new.index]\n",
    "                df_new[row.new_column] = newcol\n",
    "                df_diff[row.new_column] = newcol\n",
    "\n",
    "        elif row.action == 'add always':\n",
    "            # add new column always\n",
    "            newcol = [df_refined.loc[i, row.new_column] for i in df_new.index]\n",
    "            df_new[row.new_column] = newcol\n",
    "            df_diff[row.new_column] = newcol\n",
    "\n",
    "        elif row.action == 'add if':\n",
    "            # add new column if old column exists\n",
    "            if np.any([x in df_new.columns for x in old_cols]):\n",
    "                newcol = [df_refined.loc[i, row.new_column] for i in df_new.index]\n",
    "                df_new[row.new_column] = newcol\n",
    "                df_diff[row.new_column] = newcol\n",
    "\n",
    "    # fill NaNs with 'Not applicable' (Qiita terminology)\n",
    "    df_new.fillna('Not applicable', inplace=True)\n",
    "    df_diff.fillna('Not applicable', inplace=True)\n",
    "\n",
    "    # reorder columns alphabetically (Qiita style)\n",
    "    df_new = df_new[df_new.columns.sort_values()]\n",
    "    df_diff = df_diff[df_diff.columns.sort_values()]\n",
    "\n",
    "    # write to tsv\n",
    "    df_new.to_csv('../../data/metadata-refine/metadata-sample-info-refined/%s_sample_info.tsv' % str(study_id), sep='\\t', index=True)\n",
    "    df_diff.to_csv('../../data/metadata-refine/metadata-sample-info-diff/%s_sample_info_diff.tsv' % str(study_id), sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export action columns for problem studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cols = list(df_plan.new_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_refined[df_refined.study_id.isin(problem_studies)][new_cols].to_csv(\n",
    "    '../../data/metadata-refine/qiita_metadata_for_problem_studies.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:emp-py3]",
   "language": "python",
   "name": "conda-env-emp-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
